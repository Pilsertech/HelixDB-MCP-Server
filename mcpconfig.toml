# Example MCP Server Configuration
# Copy this to mcpconfig.toml and customize

[server]
name = "AI Memory Layer MCP Server"
version = "0.1.0"

# Transport mode: "stdio", "tcp", or "http" (for single mode only)
# For multiple transports, use enable_tcp and enable_http flags below
transport = "stdio"  # Default fallback

# Enable multiple transports simultaneously
enable_tcp = true   # Enable TCP server
enable_http = true  # Enable HTTP server

# TCP configuration
tcp_host = "127.0.0.1"
tcp_port = 8765  # TCP server port
tcp_nodelay = true  # Disable Nagle's algorithm for low latency
tcp_keepalive = true  # Detect broken connections
tcp_keepalive_idle = 60  # Seconds before probing
tcp_keepalive_interval = 10  # Seconds between probes

# HTTP configuration
http_host = "127.0.0.1"
http_port = 9527  # HTTP server port

[helix]
# HelixDB connection settings
endpoint = "127.0.0.1"
port = 6969

# ============================================================================
# EMBEDDING CONFIGURATION - Choose your mode
# ============================================================================

[embedding]
# OPTION 1: MCP Mode with Local Embedding Server (Your setup)
# ----------------------------------------------------------------
# MCP server will generate embeddings using local embedding server
mode = "mcp"
provider = "local"
model = "All MiniLM L6 v2"
local_api_url = "http://127.0.0.1:8699/embed"

# The embedding server expects POST to /embed with:
# {"text": "your text", "chunk_style": "recursive", "chunk_size": 100}
# Response: {"embedding": [0.1, 0.2, ...]}


# OPTION 2: HelixDB Mode (Alternative)
# ----------------------------------------------------
# Uncomment below for HelixDB to handle embeddings
# mode = "helixdb"


# OPTION 3: MCP Mode with OpenAI/Gemini (Alternative)
# -----------------------------------------------
# MCP server will handle embedding generation before sending to HelixDB
# mode = "mcp"
# provider = "openai"  # Options: "openai", "gemini", "local"
# model = "text-embedding-3-small"
# api_key = ""  # Leave empty to use OPENAI_API_KEY env variable
# dimensions = 1536

# Note: Set your OpenAI API key in environment: $env:OPENAI_API_KEY = "sk-..."


# ============================================================================
# QUICK START GUIDE
# ============================================================================
# 
# 1. Copy this file to mcpconfig.toml
# 2. Keep mode = "helixdb" (already set above)
# 3. Add to your helix.toml: embedding_model = "text-embedding-ada-002"
# 4. Set API key: $env:OPENAI_API_KEY = "sk-proj-..."
# 5. Start the server
# 
# That's it! Semantic search will work automatically.
# ============================================================================
